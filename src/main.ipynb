{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import svd\n",
    "\n",
    "from abc import ABC\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Change these variables to change how the notebook is run.\n",
    "\n",
    "- `run_best_only`\n",
    "    - Set to `True` to run the best classifier only, and save the test set predictions to the Output folder. This setting should be used for benchmarking the time taken to run the notebook, \n",
    "    - Set to `False` to run all classifiers, and output statistics. This is the setting that was used to collect statistics for our report. This setting will not run any classifiers on the provided test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_best_only = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Notebook\n",
    "\n",
    "The notebook should be placed in the following directory structure:\n",
    "\n",
    "- Algorithm\n",
    "    - notebook (this file)\n",
    "    - Input\n",
    "        - images_training.h5\n",
    "        - labels_training.h5\n",
    "        - images_testing.h5\n",
    "    - Output\n",
    "        - predicted_labels.h5\n",
    "        \n",
    "`images_training.h5` is the set of 30000 28x28 images used for training the models.\n",
    "\n",
    "`labels_training.h5` is the corresponding set of 30000 labels used for training the models.\n",
    "\n",
    "`images_testing.h5` is the test set of 10000 labels used for testing the models.\n",
    "\n",
    "`predicted_labels.h5` is a file generated by the best classifier in this notebook, when the `run_best_only` flag is set to `True`. It contains the predicted outputs of the 10000 test images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "Load training and testing data from the four provided files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with h5py.File('./Input/images_training.h5', 'r') as h:\n",
    "        train_data = np.copy(h['datatrain'])\n",
    "\n",
    "    with h5py.File('./Input/labels_training.h5', 'r') as h:\n",
    "        train_labels = np.copy(h['labeltrain'])\n",
    "\n",
    "    with h5py.File('./Input/images_testing.h5', 'r') as h:\n",
    "        test_data = np.copy(h['datatest'])\n",
    "\n",
    "    return train_data, train_labels, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Stratified folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stratified_folds(x: np.ndarray, y: np.ndarray, n: int=10):\n",
    "    y = y[:, np.newaxis]\n",
    "    data = np.concatenate((x, y), axis=1)\n",
    "    classes = np.unique(y)\n",
    "    class_split = []\n",
    "    folds = [[] for i in range(n)]\n",
    "\n",
    "    leftover = []\n",
    "\n",
    "    for c in classes:\n",
    "        # Split dataset by class and get n folds for each class\n",
    "        c_data = data[data[:, -1] == c]\n",
    "        split_size = int(c_data.shape[0] / n)\n",
    "        split_idxs = list(range(split_size, c_data.shape[0], split_size))\n",
    "        c_data_split = np.array_split(c_data, split_idxs)\n",
    "\n",
    "        # Take out any samples that are leftover.\n",
    "        # These will be added in at the end to ensure\n",
    "        # proper stratification of folds.\n",
    "        remainder  = c_data.shape[0] % n\n",
    "        if remainder != 0:\n",
    "            leftover_split = c_data_split.pop()\n",
    "            leftover.append(leftover_split)\n",
    "\n",
    "        # Merge n folds for each class into n folds containing all classes\n",
    "        class_split.append(c_data_split)\n",
    "        fold_idx = 0\n",
    "        for split in c_data_split:\n",
    "            folds[fold_idx].append(split)\n",
    "            fold_idx += 1\n",
    "\n",
    "    # Turn folds to numpy arrays\n",
    "    folds_np = []\n",
    "    for fold in folds:\n",
    "        fold_np = np.concatenate(fold)\n",
    "        folds_np.append(fold_np)\n",
    "\n",
    "    # Distribute leftovers across folds.\n",
    "    leftover = np.concatenate(leftover)\n",
    "    for i in range(leftover.shape[0]):\n",
    "        fold_idx = i % n\n",
    "        leftover_split = leftover[i][np.newaxis, :]\n",
    "        folds_np[fold_idx] = np.concatenate([folds_np[fold_idx], leftover_split])\n",
    "\n",
    "    # Prove folds are stratified.\n",
    "    # for fold in folds_np:\n",
    "    #     print(fold.shape)\n",
    "    #     unique, counts = np.unique(fold[:, -1], return_counts=True)\n",
    "    #     print(tuple(zip(unique, counts)))\n",
    "    #     print()\n",
    "\n",
    "    folds_np = np.stack(folds_np)\n",
    "    return folds_np[:, :, :-1], folds_np[:, :, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(x: np.ndarray, y:  np.ndarray):\n",
    "    y = y[:, np.newaxis]\n",
    "    data = np.concatenate((x, y), axis=1)\n",
    "    np.random.shuffle(data)\n",
    "    return data[:,:-1], data[:,data.shape[1]-1:].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass to binary class conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_partition_by_class(x: np.ndarray, y: np.ndarray, partition_map: set):\n",
    "    classes = np.unique(y)\n",
    "    for c in partition_map:\n",
    "        if c not in classes:\n",
    "            raise ValueError('Value {} in parition_map was not found in y.'.format(c))\n",
    "\n",
    "    partition = np.copy(y)\n",
    "    for c in partition_map:\n",
    "        partition = (partition==c).astype('uint8')\n",
    "\n",
    "    return x, partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns projected vector, explained variance for all components\n",
    "# PCA based on SVD in order to save computational resources and have more accurate results#\n",
    "# Reference (with links to papers) https://stats.stackexchange.com/questions/79043/why-pca-of-data-by-means-of-svd-of-the-data\n",
    "def PCA(A: np.ndarray, n_components=6):\n",
    "    E = np.mean(A, axis=0)\n",
    "    C = A - E\n",
    "    u, s, v = svd(C)\n",
    "\n",
    "    explained_var = np.cumsum(s) / np.sum(s)\n",
    "    proj_A = np.dot(C,v[:,range(0,n_components)])\n",
    "\n",
    "    return proj_A, explained_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "Define helper functions and classes to be used by the different classifiers. These include:\n",
    "\n",
    "- **Distance functions**\n",
    "    - Manhattan distance\n",
    "    - Euclidean distance\n",
    "    - Squared Euclidean distance\n",
    "    - Minkowski distance\n",
    "\n",
    "- **Activation functions**\n",
    "    - Sigmoid\n",
    "    - tanh\n",
    "    - Relu\n",
    "    - Softplus\n",
    "    \n",
    "- **Error functions**\n",
    "    - Squared error\n",
    "    \n",
    "- **Metrics**\n",
    "    - Accuracy\n",
    "    - Confusion matrix\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1\n",
    "\n",
    "### Distance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan(x: np.ndarray, y: np.ndarray, axis: int):\n",
    "    return np.sum(np.abs(x - y), axis=axis)\n",
    "\n",
    "def euclidean(x: np.ndarray, y: np.ndarray, axis: int):\n",
    "    return minkowski(x, y, 2, axis=axis)\n",
    "\n",
    "def euclidean_squared(x: np.ndarray, y: np.ndarray, axis: int):\n",
    "    return np.sum(np.abs(x - y)**2, axis=axis)\n",
    "\n",
    "def minkowski(x: np.ndarray, y: np.ndarray, pow: int, axis: int):\n",
    "    return np.sum(np.abs(x - y)**pow, axis=axis)**(1/pow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction:\n",
    "\n",
    "    def __init__(self, func: callable, d_func: callable):\n",
    "        self.func = func\n",
    "        self.d_func = d_func\n",
    "\n",
    "def f_sigmoid(x: np.array):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def df_sigmoid(x: np.array):\n",
    "    sig_x = f_sigmoid(x)\n",
    "    return sig_x * (1 - sig_x)\n",
    "\n",
    "def f_tanh(x: np.array):\n",
    "    e_nx = np.exp(-x)\n",
    "    e_x = np.exp(x)\n",
    "    return (e_x - e_nx)/(e_x + e_nx)\n",
    "\n",
    "def df_tanh(x: np.array):\n",
    "    tanh_x = f_tanh(x)\n",
    "    return 1 - tanh_x**2\n",
    "\n",
    "def f_relu(x: np.array):\n",
    "    x_copy = np.copy(x)\n",
    "    x_copy[x_copy<0] = 0\n",
    "    return x_copy\n",
    "\n",
    "def df_relu(x: np.array):\n",
    "    ret = (x > 0).astype(int)\n",
    "    return ret\n",
    "\n",
    "def f_softplus(x: np.array):\n",
    "    e_x = np.exp(x)\n",
    "    return np.log(1 + e_x)\n",
    "\n",
    "def df_softplus(x: np.array):\n",
    "    return f_sigmoid(x)\n",
    "\n",
    "\n",
    "sigmoid = ActivationFunction(f_sigmoid, df_sigmoid)\n",
    "tanh = ActivationFunction(f_tanh, df_tanh)\n",
    "relu = ActivationFunction(f_relu, df_relu)\n",
    "softplus = ActivationFunction(f_softplus, df_softplus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorFunction:\n",
    "\n",
    "    def __init__(self, func: callable, d_func: callable):\n",
    "        self.func = func\n",
    "        self.d_func = d_func\n",
    "\n",
    "def f_sse(predicted: np.ndarray, actual: np.ndarray):\n",
    "    return 0.5*(actual - predicted)**2\n",
    "\n",
    "def df_sse(predicted: np.ndarray, actual: np.ndarray):\n",
    "    return actual - predicted\n",
    "\n",
    "sse = ErrorFunction(f_sse, df_sse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    if (y_hat.shape == y.shape):\n",
    "        pred = (y_hat == y)\n",
    "        return len(np.where(pred == True)[0]) / len(y)\n",
    "\n",
    "def confusion_matrix(y_hat, y):\n",
    "    if (y_hat.shape == y.shape):\n",
    "        classes = set(np.unique(y_hat)).intersection(np.unique(y))\n",
    "\n",
    "        mat = [[None for c in classes] for c_hat in classes]\n",
    "        c_hat_idx = 0\n",
    "\n",
    "        for c_hat in classes:\n",
    "            y_hat_equal_c_hat = y_hat == c_hat\n",
    "            c_idx = 0\n",
    "            for c in classes:\n",
    "                y_equal_c = y == c\n",
    "                mat_entry = np.sum(y_hat_equal_c_hat * y_equal_c)\n",
    "                # Actual count of class c is sum of column\n",
    "                # Num samples predicted as class c_hat is sum of row\n",
    "                mat[c_hat_idx][c_idx] = mat_entry\n",
    "                c_idx += 1\n",
    "            c_hat_idx += 1\n",
    "\n",
    "        mat = np.asarray(mat)\n",
    "        return mat, classes\n",
    "\n",
    "def recall(y_hat, y):\n",
    "    if (y_hat.shape == y.shape):\n",
    "        conf_mat, classes = confusion_matrix(y_hat, y)\n",
    "        return np.diagonal(conf_mat) / np.sum(conf_mat, axis=0)\n",
    "\n",
    "def precision(y_hat, y):\n",
    "    if (y_hat.shape == y.shape):\n",
    "        conf_mat, classes = confusion_matrix(y_hat, y)\n",
    "        return np.diagonal(conf_mat) / np.sum(conf_mat, axis=1)\n",
    "\n",
    "def f1_score(y_hat, y):\n",
    "    if (y_hat.shape == y.shape):\n",
    "        r = recall(y_hat, y)\n",
    "        p = precision(y_hat, y)\n",
    "        return (2 * p * r) / (p + r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Six different models were implemented:\n",
    " \n",
    "- Linear SVM (Applied to this dataset using the one-versus-rest approach)\n",
    "- Binary logistic regression (Applied to this dataset using the one-versus-rest approach)\n",
    "- Multinomial logistic regression\n",
    "- Naive Bayes\n",
    "- K-Nearest neighbour\n",
    "- Neural Network\n",
    "\n",
    "#### Classifier interface\n",
    "Each model conforms to a `Classifier` interface, which has a `train` and a `predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(ABC):\n",
    "\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the class of each row of data in x.\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def train(self, x: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Train the classifier on a dataset x and corresponding labels y.\n",
    "        \"\"\"\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Versus Rest\n",
    "Define a **one-versus-rest ensemble** that takes $n$ binary classifiers, where $n$ is the number of classes in the dataset (10 for the MNIST-Fashion dataset).\n",
    "\n",
    "The $k$th binary classifier is trained on a modified dataset, where class $c_k$ is relabelled as 0 and all other classes are relabelled as 1.\n",
    "\n",
    "Once all classifiers have been trained, new samples are classified by calling the `predict` method on each of the $n$ classifiers, where the $k$th classifier returns a probability that the data sample belongs to class $c_k$. The largest of these probabilities becomes the predicted class for the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneVersusRest(Classifier):\n",
    "\n",
    "    def __init__(self, binary_classifier: Classifier, output=True):\n",
    "        self.classifier = binary_classifier\n",
    "        self.classifiers = []\n",
    "        self.output = output\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the class of each row of data in x.\n",
    "        \"\"\"\n",
    "        probs = []\n",
    "        for c in self.classifiers:\n",
    "            c_classes, c_prob = c.predict(x)\n",
    "            probs.append(c_prob)\n",
    "\n",
    "        probs = np.asarray(probs)\n",
    "        predictions = np.argmax(probs, axis=0)\n",
    "        return predictions, probs\n",
    "\n",
    "    def train(self, x: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Train the classifier on a dataset x and corresponding labels y.\n",
    "        \"\"\"\n",
    "        self.classifiers = []\n",
    "\n",
    "        classes = np.unique(y)\n",
    "        c_idx = 0\n",
    "        for c in classes:\n",
    "            c_idx += 1\n",
    "            if self.output:\n",
    "                print('Training binary classifier {} of {}'.format(c_idx, len(classes)))\n",
    "            classifier_copy = deepcopy(self.classifier)\n",
    "            data, labels = binary_partition_by_class(x, y, {c,})\n",
    "            classifier_copy.train(data, labels)\n",
    "            self.classifiers.append(classifier_copy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSVM(Classifier):\n",
    "\n",
    "    # 'alpha' - learning rate of the classifier\n",
    "    # 'features' - features wanted from feature selection via PCA\n",
    "    def __init__(self, alpha = 0.01, features = 180):\n",
    "        self.alpha = alpha\n",
    "        self.features = features\n",
    "        return\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the class of each row of data in x.\n",
    "        \"\"\"\n",
    "\n",
    "        # Select only a subset of features\n",
    "        print('Performing PCA on test data. This may take a minute or two...')\n",
    "        new_x, exp_var = PCA(x, self.features)\n",
    "        w = self.weights[0:len(x),:]\n",
    "        \n",
    "        # Predict classes using trained weights\n",
    "        predicted_y = 0\n",
    "        for i in range(self.features):\n",
    "                cur_w = w[:,i].reshape(len(x), 1)\n",
    "                cur_x = new_x[:,i].reshape(len(x), 1)\n",
    "                y_pred += cur_w + cur_x\n",
    "\n",
    "        # Enter predicted classes\n",
    "        predictions = []\n",
    "        for i in predicted_y:\n",
    "            if i > 1:\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(-1)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def train(self, x: np.ndarray, y: np.ndarray, epochs=1):\n",
    "        \"\"\"\n",
    "        Train the classifier on a dataset x and corresponding labels y.\n",
    "        \"\"\"\n",
    "\n",
    "        # Select only a subset of features\n",
    "        print('Performing PCA on training data. This may take a minute or two...')\n",
    "        new_x, exp_var = PCA(x, self.features)\n",
    "\n",
    "        new_y = y.reshape(len(x), 1)\n",
    "        w = np.zeros((len(x), self.features))\n",
    "\n",
    "        for e in range(1, epochs+1):\n",
    "            print('Performing epoch {}...'.format(e))\n",
    "\n",
    "            # Calculate predicted y from current weight\n",
    "            cur_y = 0\n",
    "            for i in range(self.features):\n",
    "                cur_w = w[:,i].reshape(len(x), 1)\n",
    "                cur_x = new_x[:,i].reshape(len(x), 1)\n",
    "                cur_y += cur_w + cur_x\n",
    "\n",
    "            product = cur_y * new_y\n",
    "\n",
    "            # Adjust weights\n",
    "            for i, v in enumerate(product):\n",
    "                \n",
    "                # When correctly classified\n",
    "                if v >= 1:\n",
    "                    for j in range(self.features):\n",
    "                        cur_w = w[:,j].reshape(len(x), 1)\n",
    "                        cur_x = new_x[:,j].reshape(len(x), 1)\n",
    "                        cur_w = cur_w - self.alpha * (2 * 1 / e * cur_w)\n",
    "                        w[:,j] = np.squeeze(cur_w)\n",
    "\n",
    "                # When incorrectly classified\n",
    "                else:\n",
    "                    for j in range(self.features):\n",
    "                        cur_w = w[:,j].reshape(len(x), 1)\n",
    "                        cur_x = new_x[:,j].reshape(len(x), 1)\n",
    "                        cur_w = cur_w + self.alpha * (cur_w[i] * new_y[i] - 2 * 1 / e * cur_w)\n",
    "                        w[:,j] = np.squeeze(cur_w)\n",
    "\n",
    "        self.weights = w\n",
    "        print('Successfully trained weights for Linear SVM.')\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(Classifier):\n",
    "\n",
    "    def __init__(self, input_size: int, eta=0.01, activation=sigmoid, batch_size=64, epochs=25, output=True):\n",
    "        # Validate input_size\n",
    "        if type(input_size) != int:\n",
    "            raise TypeError('Invalid type for param input_size, expected {}'.format(int))\n",
    "        if input_size <= 0:\n",
    "            raise ValueError('Parameter input_size must be positive')\n",
    "\n",
    "        # Validate eta\n",
    "        if type(eta) != float:\n",
    "            raise TypeError('Invalid type for param eta, expected {}'.format(float))\n",
    "        if eta <= 0:\n",
    "            raise ValueError('Parameter eta must be positive')\n",
    "\n",
    "        # Ensure batch_size is > 0\n",
    "        if type(batch_size) != int:\n",
    "            raise TypeError('Invalid type for param batch_size, expected {}'.format(int))\n",
    "        if batch_size <= 0:\n",
    "            raise ValueError('Parameter batch_size must be positive')\n",
    "\n",
    "        # Ensure epochs is > 0\n",
    "        if type(epochs) != int:\n",
    "            raise TypeError('Invalid type for param epochs, expected {}'.format(int))\n",
    "        if epochs <= 0:\n",
    "            raise ValueError('Parameter epochs must be positive')\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.eta = eta\n",
    "        self.activation = activation\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "\n",
    "        self.weights = None\n",
    "        self.output = output\n",
    "        self.randomise()\n",
    "\n",
    "    def randomise(self):\n",
    "        \"\"\"\n",
    "        Randomly initialise the layer's weights and biases.\n",
    "        \"\"\"\n",
    "        self.weights = np.random.standard_normal((self.input_size + 1,))\n",
    "\n",
    "    def adjust_weights(self, dw: np.ndarray):\n",
    "        \n",
    "        if dw.shape != self.weights.shape:\n",
    "            raise ValueError('Expected param dw of shape {} but got {}'.format(self.weights.shape, dw.shape))\n",
    "\n",
    "        self.weights += self.eta * dw\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the class of each row of data in x.\n",
    "        \"\"\"\n",
    "        ones = np.ones((x.shape[0], 1))\n",
    "        x_tilde = np.hstack((x, ones))\n",
    "        probability = self.activation.func(x_tilde @ self.weights[:, np.newaxis]).squeeze()\n",
    "        return np.round(probability).astype('uint8'), probability\n",
    "\n",
    "    def train(self, x: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Train the classifier on a dataset x and corresponding labels y.\n",
    "        \"\"\"\n",
    "\n",
    "        classes = np.unique(y)\n",
    "        if len(classes) != 2:\n",
    "            raise ValueError('Expected 2 unique classes in param y but got {}.'.format(len(classes)))\n",
    "\n",
    "        y_idxs = y\n",
    "        y_idxs[y_idxs==classes[0]] = 0\n",
    "        y_idxs[y_idxs==classes[1]] = 1\n",
    "        \n",
    "        if self.output:\n",
    "            print('Training started')\n",
    "            \n",
    "        epoch_accs = [0,]\n",
    "        epoch_times = []\n",
    "        \n",
    "        epoch_idx = 0\n",
    "        for e in range(self.epochs):\n",
    "\n",
    "            data, lbl = shuffle_data(x, y_idxs)\n",
    "            epoch_correct = 0\n",
    "            epoch_start = time.perf_counter()\n",
    "\n",
    "            data_split = np.split(data, range(self.batch_size, len(x), self.batch_size))\n",
    "            lbl_split = np.split(lbl, range(self.batch_size, len(x), self.batch_size))\n",
    "\n",
    "            batch_idx = 0\n",
    "            while batch_idx < len(data_split):\n",
    "\n",
    "                batch = data_split[batch_idx]\n",
    "                batch_lbls = lbl_split[batch_idx]\n",
    "\n",
    "                batch_pred_lbls, batch_pred_probs = self.predict(batch)\n",
    "\n",
    "                batch_correct = (batch_pred_lbls == batch_lbls).sum()\n",
    "\n",
    "                err = batch_pred_probs - batch_lbls\n",
    "\n",
    "                ones = np.ones((batch.shape[0], 1))\n",
    "                batch_tilde = np.hstack((batch, ones))\n",
    "                dw = -np.sum(batch_tilde.T * err, axis=1)\n",
    "                self.adjust_weights(dw)\n",
    "\n",
    "                epoch_correct += batch_correct\n",
    "                batch_idx += 1\n",
    "\n",
    "            epoch_idx += 1\n",
    "            epoch_end = time.perf_counter()\n",
    "\n",
    "            epoch_acc = epoch_correct/x.shape[0]\n",
    "            epoch_time = epoch_end - epoch_start\n",
    "            \n",
    "            epoch_accs.append(epoch_acc)\n",
    "            epoch_times.append(epoch_time)\n",
    "\n",
    "            if self.output:\n",
    "                print()\n",
    "                print('Epoch {} complete in {:.3f}s'.format(e+1, epoch_time))\n",
    "                print('Accuracy: {:.2f}%'.format(epoch_acc * 100))\n",
    "        \n",
    "        # Return epoch accuracies and epoch time\n",
    "        return epoch_accs, epoch_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialLogisticRegression(Classifier):\n",
    "\n",
    "    def __init__(self, input_size: int, n_classes: int, eta=0.01, batch_size=64, epochs=25, output=True):\n",
    "        # Validate input_size\n",
    "        if type(input_size) != int:\n",
    "            raise TypeError('Invalid type for param input_size, expected {}'.format(int))\n",
    "        if input_size <= 0:\n",
    "            raise ValueError('Parameter input_size must be positive')\n",
    "\n",
    "        # Validate n_classes\n",
    "        if type(n_classes) != int:\n",
    "            raise TypeError('Invalid type for param n_classes, expected {}'.format(int))\n",
    "        if n_classes <= 0:\n",
    "            raise ValueError('Parameter n_classes must be positive')\n",
    "\n",
    "        # Validate eta\n",
    "        if type(eta) != float:\n",
    "            raise TypeError('Invalid type for param eta, expected {}'.format(float))\n",
    "        if eta <= 0:\n",
    "            raise ValueError('Parameter eta must be positive')\n",
    "\n",
    "        # Ensure batch_size is > 0\n",
    "        if type(batch_size) != int:\n",
    "            raise TypeError('Invalid type for param batch_size, expected {}'.format(int))\n",
    "        if batch_size <= 0:\n",
    "            raise ValueError('Parameter batch_size must be positive')\n",
    "\n",
    "        # Ensure epochs is > 0\n",
    "        if type(epochs) != int:\n",
    "            raise TypeError('Invalid type for param epochs, expected {}'.format(int))\n",
    "        if epochs <= 0:\n",
    "            raise ValueError('Parameter epochs must be positive')\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.n_classes = n_classes\n",
    "        self.eta = eta\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.output = output\n",
    "        self.weights = None\n",
    "        self.randomise()\n",
    "\n",
    "    def randomise(self):\n",
    "        \"\"\"\n",
    "        Randomly initialise the layer's weights and biases.\n",
    "        \"\"\"\n",
    "        self.weights = np.random.standard_normal((self.input_size + 1, self.n_classes))\n",
    "\n",
    "    def adjust_weights(self, dw: np.ndarray):\n",
    "        \n",
    "        if dw.shape != self.weights.shape:\n",
    "            raise ValueError('Expected param dw of shape {} but got {}'.format(self.weights.shape, dw.shape))\n",
    "\n",
    "        self.weights += self.eta * dw\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the class of each row of data in x.\n",
    "        \"\"\"\n",
    "        ones = np.ones((x.shape[0], 1))\n",
    "        x_tilde = np.hstack((x, ones))\n",
    "        probabilities = x_tilde @ self.weights\n",
    "        #print(probabilities)\n",
    "        return np.argmax(probabilities, axis=1), probabilities\n",
    "\n",
    "    def train(self, x: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Train the classifier on a dataset x and corresponding labels y.\n",
    "        \"\"\"\n",
    "\n",
    "        classes = np.unique(y)\n",
    "        if len(classes) != self.n_classes:\n",
    "            raise ValueError('Expected {} unique classes in param y but got {}.'.format(self.n_classes, len(classes)))\n",
    "\n",
    "        if self.output:\n",
    "            print('Training started')\n",
    "        epoch_accs = [0,]\n",
    "        epoch_times = []\n",
    "        \n",
    "        epoch_idx = 0\n",
    "        for e in range(self.epochs):\n",
    "\n",
    "            data, lbl = shuffle_data(x, y)\n",
    "            epoch_correct = 0\n",
    "            epoch_start = time.perf_counter()\n",
    "\n",
    "            data_split = np.split(data, range(self.batch_size, len(x), self.batch_size))\n",
    "            lbl_split = np.split(lbl, range(self.batch_size, len(x), self.batch_size))\n",
    "\n",
    "            batch_idx = 0\n",
    "            while batch_idx < len(data_split):\n",
    "\n",
    "                batch = data_split[batch_idx]\n",
    "                batch_lbls = lbl_split[batch_idx]\n",
    "\n",
    "                batch_pred_lbls, batch_pred_probs = self.predict(batch)\n",
    "\n",
    "                batch_correct = (batch_pred_lbls == batch_lbls).sum()\n",
    "                batch_actual = np.zeros(batch_pred_probs.shape)\n",
    "                for i in range(batch_actual.shape[1]):\n",
    "                    batch_actual[batch_lbls.T.squeeze() == i, i] = 1\n",
    "\n",
    "                # Compute weight changes for weights for each class\n",
    "                # https://math.stackexchange.com/questions/1428344/what-is-the-derivation-of-the-derivative-of-softmax-regression-or-multinomial-l/2081449\n",
    "                e_pred = np.exp(batch_pred_probs)\n",
    "                d_logs = batch_actual - e_pred/np.sum(e_pred, axis=1)[:, np.newaxis]\n",
    "                ones = np.ones((batch.shape[0], 1))\n",
    "                batch_tilde = np.hstack((batch, ones))\n",
    "                dw = (batch_tilde.T @ d_logs)\n",
    "\n",
    "                self.adjust_weights(dw)\n",
    "\n",
    "                epoch_correct += batch_correct\n",
    "                batch_idx += 1\n",
    "\n",
    "            epoch_idx += 1\n",
    "            epoch_end = time.perf_counter()\n",
    "            \n",
    "            epoch_acc = epoch_correct/x.shape[0]\n",
    "            epoch_time = epoch_end - epoch_start\n",
    "            \n",
    "            epoch_accs.append(epoch_acc)\n",
    "            epoch_times.append(epoch_time)\n",
    "\n",
    "            if self.output:\n",
    "                print()\n",
    "                print('Epoch {} complete in {:.3f}s'.format(e+1, epoch_time))\n",
    "                print('Accuracy: {:.2f}%'.format(epoch_acc * 100))\n",
    "        \n",
    "        # Return epoch accuracies and epoch time\n",
    "        return epoch_accs, epoch_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayes(Classifier):\n",
    "\n",
    "    def __init__(self, alpha=1.0):\n",
    "        # Additive (Laplace/Lidstone) smoothing parameter,\n",
    "        # used to avoid zero theta_ck probabilities. Works\n",
    "        # better for larger training sets.\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def train(self, x: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Compute prior (pi_k) probability for the classes in y,\n",
    "        and posterior (theta_ck) probabilities for attributes given classes.\n",
    "\n",
    "        These are used to predict the class of new samples.\n",
    "        \"\"\"\n",
    "        # Separate into classes\n",
    "        self.classes = np.unique(y)        \n",
    "        data_by_class = [[data for data, lbl in zip(x, y) if lbl == c] for c in self.classes]\n",
    "        \n",
    "        # Compute prior probabilities\n",
    "        data_count = x.shape[0]\n",
    "        self.pi_c = np.array([len(class_data) / data_count for class_data in data_by_class])\n",
    "        \n",
    "        # Compute posterior probabilities\n",
    "        attrib_counts_by_class = np.array([np.sum(class_data, axis=0) for class_data in data_by_class]) + self.alpha\n",
    "        total_counts_by_class = np.sum(attrib_counts_by_class, axis=1)\n",
    "        self.theta_ck = attrib_counts_by_class / total_counts_by_class[:, np.newaxis]\n",
    "\n",
    "    def get_log_likelihood(self, x):\n",
    "        \"\"\"\n",
    "        Get the log-likelihood for a new set of data x.\n",
    "        \"\"\"\n",
    "\n",
    "        log_pi_c = np.log(self.pi_c)\n",
    "        log_theta_ck = np.log(self.theta_ck)\n",
    "\n",
    "        # Sum up x_k theta_k for each class for each sample,\n",
    "        # then add log_pi_c for each sample.\n",
    "        return (log_theta_ck @ x.T + log_pi_c[:, np.newaxis]).T\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        return np.argmax(self.get_log_likelihood(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestNeighbour(Classifier):\n",
    "\n",
    "    def __init__(self, k: int, dist: callable=euclidean_squared):\n",
    "        if k <= 0:\n",
    "            raise ValueError('Parameter k must be greater than 0.')\n",
    "\n",
    "        self.k = k\n",
    "        self.data = None\n",
    "        self.classes = None\n",
    "        self.dist = dist\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"\n",
    "        Reset all classifier parameters to their defaults.\n",
    "        \"\"\"\n",
    "        self.data = None\n",
    "        self.classes = None\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the class of each row of data in x.\n",
    "        \"\"\"\n",
    "        if x.shape[1] != self.data.shape[1]:\n",
    "            raise ValueError('Invalid dimension of param x, expected {} but got {}'.format(self.data.shape[1], x.shape[1]))\n",
    "        \n",
    "        start = time.perf_counter()\n",
    "        predictions = np.apply_along_axis(self.__predict_single, 1, x)\n",
    "        end = time.perf_counter()\n",
    "        print('Predicted {} samples in {}s'.format(x.shape[0], end - start))\n",
    "        return predictions\n",
    "\n",
    "    def __predict_single(self, x: np.ndarray) -> np.ndarray:\n",
    "        dst = self.dist(self.data, x, axis=1)\n",
    "        k_smallest = np.argpartition(dst, self.k)[:self.k]\n",
    "        k_classes = self.classes[k_smallest]\n",
    "        return np.argmax(np.bincount(k_classes))\n",
    "\n",
    "\n",
    "    def train(self, x: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Train the classifier on a dataset x and corresponding labels y.\n",
    "        K-Nearest-Neighbour is a lazy learning algorithm, so we simply store\n",
    "        the data for prediction later.\n",
    "        \"\"\"\n",
    "        self.data = x\n",
    "        self.classes = y.astype('uint8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "#### Neural Netowork Layer Interface\n",
    "\n",
    "Define an interface for Neural Network layers. This was originally designed with the intention of implementing dropout, pooling and Relu layers for a convolutional neural network, but time did not allow for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkLayer(ABC):\n",
    "\n",
    "    def __init__(self, output_shape: tuple, activation=sigmoid):\n",
    "        # Ensure shapes are valid\n",
    "        NeuralNetworkLayer.__validate_shape(output_shape)\n",
    "        self.output_shape = output_shape\n",
    "        self.input_shape = None\n",
    "        self.activation = activation\n",
    "\n",
    "    def set_input_shape(self, shape: tuple):\n",
    "        NeuralNetworkLayer.__validate_shape(shape)\n",
    "        self.input_shape = shape\n",
    "\n",
    "    @staticmethod\n",
    "    def __validate_shape(shape: tuple):\n",
    "        for val in shape:\n",
    "            if not isinstance(val, int):\n",
    "                raise TypeError('Invalid shape, expected a tuple of ints')\n",
    "            if val <= 0:\n",
    "                raise ValueError('Invalid value in shape, expected > 0.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flat Dense Layer\n",
    "\n",
    "A typical fully connected layer for use in neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatDenseLayer(NeuralNetworkLayer):\n",
    "\n",
    "    def __init__(self, output_shape: tuple, activation=sigmoid):\n",
    "        super().__init__(output_shape, activation)\n",
    "        self.raw_outputs = None\n",
    "        self.outputs = None\n",
    "\n",
    "    @classmethod\n",
    "    def from_size(cls, size: int):\n",
    "        return cls((size,))\n",
    "\n",
    "    def randomise(self):\n",
    "        \"\"\"\n",
    "        Randomly initialise the layer's weights and biases.\n",
    "        \"\"\"\n",
    "        self.biases = None\n",
    "        self.weights = None\n",
    "\n",
    "        if self.input_shape is not None:\n",
    "            self.biases = np.random.standard_normal((self.output_shape[0], 1))\n",
    "            self.weights = np.random.standard_normal((self.output_shape[0], self.input_shape[0]))\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_valid_batch(array: np.ndarray, shape: tuple):\n",
    "        \"\"\"\n",
    "        Given a specified shape (s0, s1, ..., sk), verify that the array\n",
    "        is of shape (s0, s1, ..., sk, n).\n",
    "        \"\"\"\n",
    "        if len(array.shape) > len(shape) + 1:\n",
    "            raise ValueError('Too many dimensions in param array.')\n",
    "\n",
    "        if len(array.shape) < len(shape):\n",
    "            raise ValueError('Not enough dimensions in param array.')\n",
    "        \n",
    "        # Check if array has shape (s0, s1, ..., sk)\n",
    "        # If so, cast to shape (s0, s1, ..., sk, 1)\n",
    "        if len(array.shape) == len(shape):\n",
    "            array = array[:, np.newaxis]\n",
    "\n",
    "        if array.shape[:-1] != shape:\n",
    "            raise ValueError('Invalid shape of param array, expected {} but got {}'.format(shape, array.shape))\n",
    "        \n",
    "        return array\n",
    "\n",
    "\n",
    "    def get_activations(self, ipt: np.ndarray):\n",
    "        \"\"\"\n",
    "        Get the activations/outputs of the current layer, given the input array.\n",
    "        \"\"\"\n",
    "\n",
    "        # No input_shape implies first layer, just return the input as the output\n",
    "        if self.input_shape is None:\n",
    "            ipt = FlatDenseLayer.__get_valid_batch(ipt, self.output_shape)\n",
    "            \n",
    "            self.outputs = ipt\n",
    "            self.raw_outputs = ipt\n",
    "\n",
    "            return ipt\n",
    "\n",
    "        ipt = FlatDenseLayer.__get_valid_batch(ipt, self.input_shape)\n",
    "\n",
    "        raw_out = self.weights @ ipt + self.biases\n",
    "\n",
    "        self.raw_outputs = raw_out\n",
    "        self.outputs = self.activation.func(raw_out)\n",
    "\n",
    "        return self.outputs\n",
    "\n",
    "    def adjust_weights(self, eta: float, dw: np.ndarray, db: np.ndarray):\n",
    "        \n",
    "        if dw.shape != self.weights.shape:\n",
    "            raise ValueError('Expected param dw of shape {} but got {}'.format(self.weights.shape, dw.shape))\n",
    "        \n",
    "        if db.shape != self.biases.shape:\n",
    "            raise ValueError('Expected param db of shape {} but got {}'.format(self.biases.shape, db.shape))\n",
    "\n",
    "        self.weights += eta * dw\n",
    "        self.biases += eta * db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network Class\n",
    "\n",
    "Defines a neural network, with customisable layer structure, learning rate, activation functions, batch sizes and epoch count.\n",
    "\n",
    "The network is trained using mini-batch gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(Classifier):\n",
    "\n",
    "    def __init__(self, layers: list, eta=0.01, batch_size=64, epochs=25, output=True):\n",
    "        # Ensure layers is a ist of NeuralNetworkLayer objects\n",
    "        for l in layers:\n",
    "            if not isinstance(l, NeuralNetworkLayer):\n",
    "                raise TypeError('Invalid type in list {}, expected {}'.format(layers, NeuralNetworkLayer))\n",
    "        \n",
    "        # Validate eta\n",
    "        if type(eta) != float:\n",
    "            raise TypeError('Invalid type for param eta, expected {}'.format(float))\n",
    "        if eta <= 0:\n",
    "            raise ValueError('Parameter eta must be positive')\n",
    "        \n",
    "        # Ensure batch_size is > 0\n",
    "        if type(batch_size) != int:\n",
    "            raise TypeError('Invalid type for param batch_size, expected {}'.format(int))\n",
    "        if batch_size <= 0:\n",
    "            raise ValueError('Parameter batch_size must be positive')\n",
    "\n",
    "        # Ensure epochs is > 0\n",
    "        if type(epochs) != int:\n",
    "            raise TypeError('Invalid type for param epochs, expected {}'.format(int))\n",
    "        if epochs <= 0:\n",
    "            raise ValueError('Parameter epochs must be positive')\n",
    "        \n",
    "        self.layers = layers\n",
    "        self.eta = eta\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.output = output\n",
    "\n",
    "        # Link layers\n",
    "        i = 1\n",
    "        while i < len(self.layers):\n",
    "            self.layers[i].set_input_shape(self.layers[i-1].output_shape)\n",
    "            i += 1\n",
    "        \n",
    "        # Randomise weights\n",
    "        self.__randomise()\n",
    "\n",
    "    def __randomise(self):\n",
    "        \"\"\"\n",
    "        Randomly initialise the network's weights and biases.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            layer.randomise()\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"\n",
    "        Reset all classifier parameters to their defaults.\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the class of each row of data in x.\n",
    "        \"\"\"\n",
    "\n",
    "        activation = x.T\n",
    "        for layer in self.layers:\n",
    "            activation = layer.get_activations(activation)\n",
    "        return np.argmax(activation, axis=0), activation\n",
    "\n",
    "\n",
    "    def train(self, x: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Train the classifier on a dataset x and corresponding labels y.\n",
    "        \"\"\"\n",
    "        if self.output:\n",
    "            print('Training started')\n",
    "            \n",
    "        epoch_accs = [0,]\n",
    "        epoch_times = []\n",
    "        \n",
    "        epoch_idx = 0\n",
    "        for e in range(self.epochs):\n",
    "\n",
    "            data, lbl = shuffle_data(x, y)\n",
    "            \n",
    "            \n",
    "            epoch_correct = 0\n",
    "            epoch_start = time.perf_counter()\n",
    "\n",
    "            data_split = np.split(data, range(self.batch_size, len(x), self.batch_size))\n",
    "            lbl_split = np.split(lbl, range(self.batch_size, len(x), self.batch_size))\n",
    "\n",
    "            batch_idx = 0\n",
    "            while batch_idx < len(data_split):\n",
    "\n",
    "                batch = data_split[batch_idx]\n",
    "                batch_lbls = lbl_split[batch_idx]\n",
    "                \n",
    "                batch_pred_lbls, batch_pred = self.predict(batch)\n",
    "                batch_correct = (batch_pred_lbls == batch_lbls.squeeze()).sum()\n",
    "\n",
    "                batch_actual = np.zeros(batch_pred.shape)\n",
    "                for i in range(batch_actual.shape[0]):\n",
    "                    batch_actual[i, batch_lbls.T.squeeze() == i] = 1\n",
    "                \n",
    "                dC_da = sse.d_func(batch_pred, batch_actual)\n",
    "\n",
    "                # Iterate through layers, propagating errors\n",
    "                layer_idx = len(self.layers) - 1\n",
    "                while layer_idx > 0:\n",
    "\n",
    "                    layer = self.layers[layer_idx]\n",
    "                    prev_layer = self.layers[layer_idx-1]\n",
    "\n",
    "                    # Compute weight changes using chain rule\n",
    "                    d_sigma = layer.activation.d_func(layer.raw_outputs)\n",
    "                    dC_dz = dC_da * d_sigma  # da_dz = d_sigma(z) since a = sigma(z)\n",
    "\n",
    "                    # Sum over batch to get dw for each weight.\n",
    "                    # dz_dw = x = prev_outputs.\n",
    "                    dw = dC_dz @ prev_layer.outputs.T\n",
    "\n",
    "                    # Compute bias changes\n",
    "                    # Sum over batch to get dw for each bias.\n",
    "                    # dz_dw = 1. \n",
    "                    db = dC_dz.sum(axis=1)\n",
    "                    db = db[:, np.newaxis]\n",
    "\n",
    "                    layer.adjust_weights(self.eta, dw, db)\n",
    "                    \n",
    "                    # Compute error to propagate\n",
    "                    dC_da = np.dot(layer.weights.T, dC_dz)\n",
    "\n",
    "                    layer_idx -= 1\n",
    "\n",
    "                epoch_correct += batch_correct\n",
    "                batch_idx += 1\n",
    "\n",
    "            epoch_idx += 1\n",
    "            epoch_end = time.perf_counter()\n",
    "            \n",
    "            epoch_acc = epoch_correct/x.shape[0]\n",
    "            epoch_time = epoch_end - epoch_start\n",
    "            \n",
    "            epoch_accs.append(epoch_acc)\n",
    "            epoch_times.append(epoch_time)\n",
    "\n",
    "            if self.output:\n",
    "                print()\n",
    "                print('Epoch {} complete in {:.3f}s'.format(e+1, epoch_time))\n",
    "                print('Accuracy: {:.2f}%'.format(epoch_acc * 100))\n",
    "        \n",
    "        # Return epoch accuracies and epoch time\n",
    "        return epoch_accs, epoch_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation\n",
    "\n",
    "### Load data and generate folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "train_data, train_labels, test_data = load_data()\n",
    "print('Training set data:')\n",
    "print(train_data.shape)\n",
    "print('Training set labels:')\n",
    "print(train_labels.shape)\n",
    "print('Training set labels:')\n",
    "print(test_data.shape)\n",
    "print()\n",
    "\n",
    "# Generate stratified folds\n",
    "n_folds = 10\n",
    "fold_data, fold_labels = get_stratified_folds(train_data, train_labels, n=n_folds)\n",
    "\n",
    "folds = []\n",
    "\n",
    "for i in range(n_folds):\n",
    "    fold_train_data = np.concatenate([fold_data[:i], fold_data[i + 1:]])\n",
    "    fold_train_data = np.concatenate(fold_train_data)\n",
    "\n",
    "    fold_train_labels = np.concatenate([fold_labels[:i], fold_labels[i + 1:]])\n",
    "    fold_train_labels = np.concatenate(fold_train_labels)\n",
    "\n",
    "    fold_validation_data = fold_data[i]\n",
    "    fold_validation_labels = fold_labels[i]\n",
    "\n",
    "    folds.append((fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels))\n",
    "\n",
    "print('{} folds generated successfully.'.format(n_folds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluator\n",
    "Define a function for evaluating a model and gathering relevant statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_data, train_labels, validation_data, validation_labels):\n",
    "    print(f'{model.__class__.__name__}:')\n",
    "    \n",
    "    start_train = time.perf_counter()\n",
    "    train_result = model.train(train_data, train_labels)\n",
    "    end_train = time.perf_counter()\n",
    "    train_time = end_train - start_train\n",
    "    \n",
    "    if train_result is not None:\n",
    "        # Graph epoch accuracies and times\n",
    "        epoch_accs, epoch_times = train_result\n",
    "        plot_epoch(epoch_accs, epoch_times)\n",
    "    \n",
    "    start_predict = time.perf_counter()\n",
    "    result = model.predict(validation_data)\n",
    "    end_predict = time.perf_counter()\n",
    "    predict_time = end_predict - start_predict\n",
    "\n",
    "    # Some predict methods return probabilities as well as classes,\n",
    "    # so just take the classes if that is the case.\n",
    "    if isinstance(result, tuple):\n",
    "        validation_pred = result[0]\n",
    "    else:\n",
    "        validation_pred = result\n",
    "    \n",
    "    # Print metrics\n",
    "    acc = accuracy(validation_pred, validation_labels)\n",
    "    prec = precision(validation_pred, validation_labels)\n",
    "    rcl = recall(validation_pred, validation_labels)\n",
    "    f1 = f1_score(validation_pred, validation_labels)\n",
    "    \n",
    "    print('\\nTraining time: {:.04f}s'.format(train_time))\n",
    "    print('\\nPrediction time: {:.04f}s'.format(predict_time))\n",
    "    print('\\nValidation Set Accuracy: {:.02f}%'.format(100*acc))\n",
    "    mat, classes = confusion_matrix(validation_pred, validation_labels)\n",
    "    print('\\nPrecision:\\n{}\\n'.format(np.round(prec, 4)))\n",
    "    print('Recall:\\n{}\\n'.format(np.round(rcl, 4)))\n",
    "    print('F1:\\n{}\\n'.format(np.round(f1, 4)))\n",
    "    print('Confusion Matrix:')\n",
    "    print(mat)\n",
    "    print()\n",
    "    \n",
    "    return train_time, predict_time, acc, mat, prec, rcl, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch(epoch_accs, epoch_times):\n",
    "    epoch_idxs = np.arange(0, len(epoch_accs), 1)\n",
    "    plt.figure(figsize = (20,20))\n",
    "    plt.rc('font', size=24)\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(epoch_idxs, epoch_accs, 'o-')\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.ylim(top=1)\n",
    "    plt.title('Epoch accuracy on training data')\n",
    "    plt.ylabel('Epoch accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    epoch_times.insert(0, 0)\n",
    "    plt.plot(epoch_idxs, np.cumsum(epoch_times), 'o-')\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.title('Cumulative training time across epochs')\n",
    "    plt.ylabel('Cumulative training time (s)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(predictions):\n",
    "    with h5py.File('./Output/predicted_labels.h5') as h:\n",
    "        if h['output'] is None:\n",
    "            h.create_dataset('output', data=predictions)\n",
    "        else:\n",
    "            data = h['output']\n",
    "            data[...] = predictions \n",
    "    print('Saved {} predictions.\\n'.format(predictions.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_best_classifier(train_data, train_labels, validation_data, validation_labels):\n",
    "    # Create, train and validate model\n",
    "    model = NeuralNetwork([\n",
    "        FlatDenseLayer((784,), activation=sigmoid),\n",
    "        FlatDenseLayer((100,), activation=sigmoid),\n",
    "        FlatDenseLayer((20,), activation=sigmoid),\n",
    "        FlatDenseLayer((10,), activation=sigmoid),\n",
    "    ], eta=0.05, batch_size=64, epochs=250, output=False)\n",
    "    \n",
    "    return evaluate_model(model, train_data, train_labels, validation_data, validation_labels)\n",
    "\n",
    "def test_best_classifier(train_data, train_labels, test_data):\n",
    "    # Create and train model\n",
    "    model = NeuralNetwork([\n",
    "        FlatDenseLayer((784,), activation=sigmoid),\n",
    "        FlatDenseLayer((100,), activation=sigmoid),\n",
    "        FlatDenseLayer((20,), activation=sigmoid),\n",
    "        FlatDenseLayer((10,), activation=sigmoid),\n",
    "    ], eta=0.05, batch_size=64, epochs=250, output=False)\n",
    "    model.train(train_data, train_labels)\n",
    "    \n",
    "    # Predict test set samples and save predictions\n",
    "    print('Predicting {} test samples...'.format(test_data.shape[0]))\n",
    "    result = model.predict(test_data)\n",
    "    # Some predict methods return probabilities as well as classes,\n",
    "    # so just take the classes if that is the case.\n",
    "    if isinstance(result, tuple):\n",
    "        test_pred = result[0]\n",
    "    else:\n",
    "        test_pred = result\n",
    "\n",
    "    save_predictions(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    print('EVALUATING BEST CLASSIFIER:')\n",
    "    train_time_lst = []\n",
    "    pred_time_lst = []\n",
    "    acc_lst = []\n",
    "    mat_lst = []\n",
    "    prec_lst = []\n",
    "    rcl_lst = []\n",
    "    f1_lst = []\n",
    "\n",
    "    fold_idx = 0\n",
    "    for fold in folds:\n",
    "        fold_idx += 1\n",
    "        print('FOLD {} of {}'.format(fold_idx, len(folds)))\n",
    "        fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels = fold\n",
    "        train_time, pred_time, acc, mat, prec, rcl, f1 = validate_best_classifier(fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels)\n",
    "        train_time_lst.append(train_time)\n",
    "        pred_time_lst.append(pred_time)\n",
    "        acc_lst.append(acc)\n",
    "        mat_lst.append(mat)\n",
    "        prec_lst.append(prec)\n",
    "        rcl_lst.append(rcl)\n",
    "        f1_lst.append(f1)\n",
    "\n",
    "    print()\n",
    "    print('Mean training time: {:.4f}s'.format(sum(train_time_lst)/len(train_time_lst)))\n",
    "    print()\n",
    "    print('Mean prediction time: {:.4f}s'.format(sum(pred_time_lst)/len(pred_time_lst)))\n",
    "    print()\n",
    "    print('Mean Accuracy: {:.4f}'.format(sum(acc_lst)/len(acc_lst)))\n",
    "    print()\n",
    "    print('All folds Confusion Matrix:')\n",
    "    print(np.sum(np.stack(mat_lst), axis=0))\n",
    "    print()\n",
    "    print('Mean Precision:')\n",
    "    print(np.mean(np.stack(prec_lst), axis=0))\n",
    "    print()\n",
    "    print('Mean Recall:')\n",
    "    print(np.mean(np.stack(rcl_lst), axis=0))\n",
    "    print()\n",
    "    print('Mean F1:')\n",
    "    print(np.mean(np.stack(f1_lst), axis=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_best_only:\n",
    "    print('TESTING BEST CLASSIFIER:')\n",
    "    test_best_classifier(train_data, train_labels, test_data)\n",
    "    \n",
    "    #Test loading of predicted labels:\n",
    "    with h5py.File('./Output/predicted_labels.h5', 'r') as h:\n",
    "        test_labels = np.copy(h['output'])\n",
    "    print(test_labels.shape)\n",
    "    print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All classifiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "##### Investigate Hyperparameter Effects\n",
    "Investigate the best learning rate for the Logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_and_plot_learning_rate(etas, model, train_data, train_labels, validation_data, validation_labels):\n",
    "    train_time_lst = []\n",
    "    pred_time_lst = []\n",
    "    acc_lst = []\n",
    "    mat_lst = []\n",
    "    prec_lst = []\n",
    "    rcl_lst = []\n",
    "    f1_lst = []\n",
    "\n",
    "    for eta in etas:\n",
    "        print('ETA:', eta)\n",
    "\n",
    "        # Create and train model\n",
    "        model_copy = deepcopy(model)\n",
    "        model.eta = eta\n",
    "        train_time, pred_time, acc, mat, prec, rcl, f1 = evaluate_model(model, train_data, train_labels, validation_data, validation_labels)\n",
    "\n",
    "        train_time_lst.append(train_time)\n",
    "        pred_time_lst.append(pred_time)\n",
    "        acc_lst.append(acc)\n",
    "        mat_lst.append(mat)\n",
    "        prec_lst.append(np.mean(prec))\n",
    "        rcl_lst.append(np.mean(rcl))\n",
    "        f1_lst.append(np.mean(f1))\n",
    "        \n",
    "    plt.figure(figsize = (20,20))\n",
    "    plt.rc('font', size=16)\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.plot(etas, train_time_lst, 'o-')\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.title('Learning Rate vs Training time')\n",
    "    plt.ylabel('Training time (s)')\n",
    "    plt.xlabel('Learning rate')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.plot(etas, pred_time_lst, 'o-')\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.title('Learning Rate vs Prediction time')\n",
    "    plt.ylabel('Prediction time (s)')\n",
    "    plt.xlabel('Learning rate')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.ylim(top=1)\n",
    "    plt.plot(etas, acc_lst, 'o-')\n",
    "    plt.title('Learning Rate vs Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Learning rate')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(3, 2, 4)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.ylim(top=1)\n",
    "    plt.plot(etas, prec_lst, 'o-')\n",
    "    plt.title('Learning Rate vs Class average precision')\n",
    "    plt.ylabel('Class average precision')\n",
    "    plt.xlabel('Learning rate')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(3, 2, 5)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.ylim(top=1)\n",
    "    plt.plot(etas, rcl_lst, 'o-')\n",
    "    plt.title('Learning Rate vs Class average recall')\n",
    "    plt.ylabel('Class average recall')\n",
    "    plt.xlabel('Learning rate')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(3, 2, 6)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.ylim(top=1)\n",
    "    plt.plot(etas, f1_lst, 'o-')\n",
    "    plt.title('Learning Rate vs Class average F1')\n",
    "    plt.ylabel('Class average F1')\n",
    "    plt.xlabel('Learning rate')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    etas = [0.1, 0.05, 0.025, 0.01, 0.005, 0.0025, 0.001, 0.0005, 0.00025, 0.0001]\n",
    "    epochs = 50\n",
    "    batch_size = 64\n",
    "    activation = sigmoid\n",
    "\n",
    "    # Only run on the first fold to save time, as we only want an indication of which hyperparam value is best\n",
    "    fold = folds[0]\n",
    "    fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels = fold\n",
    "    \n",
    "    lr_model = LogisticRegression(train_data.shape[1], eta=eta, activation=activation, batch_size=batch_size, epochs=epochs, output=False)\n",
    "    model = OneVersusRest(lr_model)\n",
    "    \n",
    "    optimise_and_plot_learning_rate(etas, model, fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate how many epochs to run, per classifier. This is determined by working out when the underlying binary classifiers are not improving their accuracy on the training set, and ensuring that their accuracy on the validation set is reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    fold = folds[0]\n",
    "    fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels = fold\n",
    "    classifier = LogisticRegression(fold_train_data.shape[1], eta=0.001, activation=sigmoid, batch_size=64, epochs=100, output=False)\n",
    "\n",
    "    classes = np.unique(fold_train_labels)\n",
    "    c_idx = 0\n",
    "    for c in classes:\n",
    "        c_idx += 1\n",
    "        print('Training classifier {} of {}'.format(c_idx, len(classes)))\n",
    "        classifier_copy = deepcopy(classifier)\n",
    "        c_train_data, c_train_labels = binary_partition_by_class(fold_train_data, fold_train_labels, {c,})\n",
    "        c_validation_data, c_validation_labels = binary_partition_by_class(fold_validation_data, fold_validation_labels, {c,})\n",
    "        evaluate_model(classifier_copy, c_train_data, c_train_labels, c_validation_data, c_validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_logistic_regression(train_data, train_labels, validation_data, validation_labels):\n",
    "    # Create and train model\n",
    "    lr_model = LogisticRegression(train_data.shape[1], eta=0.001, activation=sigmoid, batch_size=64, epochs=50, output=False)\n",
    "    model = OneVersusRest(lr_model)\n",
    "    return evaluate_model(model, train_data, train_labels, validation_data, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    train_time_lst = []\n",
    "    pred_time_lst = []\n",
    "    acc_lst = []\n",
    "    mat_lst = []\n",
    "    prec_lst = []\n",
    "    rcl_lst = []\n",
    "    f1_lst = []\n",
    "\n",
    "    fold_idx = 0\n",
    "    for fold in folds:\n",
    "        fold_idx += 1\n",
    "        print('FOLD {} of {}'.format(fold_idx, len(folds)))\n",
    "        fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels = fold\n",
    "        train_time, pred_time, acc, mat, prec, rcl, f1 = best_logistic_regression(fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels)\n",
    "        train_time_lst.append(train_time)\n",
    "        pred_time_lst.append(pred_time)\n",
    "        acc_lst.append(acc)\n",
    "        mat_lst.append(mat)\n",
    "        prec_lst.append(prec)\n",
    "        rcl_lst.append(rcl)\n",
    "        f1_lst.append(f1)\n",
    "\n",
    "    print()\n",
    "    print('Mean training time: {:.4f}s'.format(sum(train_time_lst)/len(train_time_lst)))\n",
    "    print()\n",
    "    print('Mean prediction time: {:.4f}s'.format(sum(pred_time_lst)/len(pred_time_lst)))\n",
    "    print()\n",
    "    print('Mean Accuracy: {:.4f}'.format(sum(acc_lst)/len(acc_lst)))\n",
    "    print()\n",
    "    print('All folds Confusion Matrix:')\n",
    "    print(np.sum(np.stack(mat_lst), axis=0))\n",
    "    print()\n",
    "    print('Mean Precision:')\n",
    "    print(np.mean(np.stack(prec_lst), axis=0))\n",
    "    print()\n",
    "    print('Mean Recall:')\n",
    "    print(np.mean(np.stack(rcl_lst), axis=0))\n",
    "    print()\n",
    "    print('Mean F1:')\n",
    "    print(np.mean(np.stack(f1_lst), axis=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression\n",
    "##### Investigate Hyperparameter Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    etas = [0.1, 0.05, 0.025, 0.01, 0.005, 0.0025, 0.001, 0.0005, 0.00025, 0.0001]\n",
    "    epochs = 250\n",
    "    batch_size = 64\n",
    "\n",
    "    model = MultinomialLogisticRegression(\n",
    "        train_data.shape[1],\n",
    "        len(np.unique(train_labels)),\n",
    "        eta=etas[0],\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        output=False\n",
    "    )\n",
    "    \n",
    "    # Only run on the first fold to save time, as we only want an indication of which hyperparam value is best\n",
    "    fold = folds[0]\n",
    "    fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels = fold\n",
    "    \n",
    "    optimise_and_plot_learning_rate(etas, model, fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_multinomial_logistic_regression(train_data, train_labels, validation_data, validation_labels):\n",
    "    # Create and train model\n",
    "    model = MultinomialLogisticRegression(\n",
    "        train_data.shape[1],\n",
    "        len(np.unique(train_labels)),\n",
    "        eta=0.05,\n",
    "        epochs=250,\n",
    "        output=False\n",
    "    )\n",
    "\n",
    "    return evaluate_model(model, train_data, train_labels, validation_data, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    train_time_lst = []\n",
    "    pred_time_lst = []\n",
    "    acc_lst = []\n",
    "    mat_lst = []\n",
    "    prec_lst = []\n",
    "    rcl_lst = []\n",
    "    f1_lst = []\n",
    "\n",
    "    fold_idx = 0\n",
    "    for fold in folds:\n",
    "        fold_idx += 1\n",
    "        print('FOLD {} of {}'.format(fold_idx, len(folds)))\n",
    "        fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels = fold\n",
    "        train_time, pred_time, acc, mat, prec, rcl, f1 = best_multinomial_logistic_regression(fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels)\n",
    "        train_time_lst.append(train_time)\n",
    "        pred_time_lst.append(pred_time)\n",
    "        acc_lst.append(acc)\n",
    "        mat_lst.append(mat)\n",
    "        prec_lst.append(prec)\n",
    "        rcl_lst.append(rcl)\n",
    "        f1_lst.append(f1)\n",
    "\n",
    "    print()\n",
    "    print('Mean training time: {:.4f}s'.format(sum(train_time_lst)/len(train_time_lst)))\n",
    "    print()\n",
    "    print('Mean prediction time: {:.4f}s'.format(sum(pred_time_lst)/len(pred_time_lst)))\n",
    "    print()\n",
    "    print('Mean Accuracy: {:.4f}'.format(sum(acc_lst)/len(acc_lst)))\n",
    "    print()\n",
    "    print('All folds Confusion Matrix:')\n",
    "    print(np.sum(np.stack(mat_lst), axis=0))\n",
    "    print()\n",
    "    print('Mean Precision:')\n",
    "    print(np.mean(np.stack(prec_lst), axis=0))\n",
    "    print()\n",
    "    print('Mean Recall:')\n",
    "    print(np.mean(np.stack(rcl_lst), axis=0))\n",
    "    print()\n",
    "    print('Mean F1:')\n",
    "    print(np.mean(np.stack(f1_lst), axis=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "##### Investigate Hyperparameter Effects\n",
    "\n",
    "There is no need to tune hyperparameters for Naive Bayes, since it is deterministic. The only parameter for Naive  Bayes is the Laplacian smoothing parameter, used to avoid zero posterior probabilities. This should be as small as possible but still nonzero, so as not to skew the posterior probabilities.\n",
    "\n",
    "##### Best Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_naive_bayes(train_data, train_labels, validation_data, validation_labels):\n",
    "    # Create and train model\n",
    "    model = MultinomialNaiveBayes()\n",
    "    return evaluate_model(model, train_data, train_labels, validation_data, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_n_fold(model_func, folds):\n",
    "    train_time_lst = []\n",
    "    pred_time_lst = []\n",
    "    acc_lst = []\n",
    "    mat_lst = []\n",
    "    prec_lst = []\n",
    "    rcl_lst = []\n",
    "    f1_lst = []\n",
    "\n",
    "    fold_idx = 0\n",
    "    for fold in folds:\n",
    "        fold_idx += 1\n",
    "        print('FOLD {} of {}'.format(fold_idx, len(folds)))\n",
    "        fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels = fold\n",
    "        train_time, pred_time, acc, mat, prec, rcl, f1 = model_func(fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels)\n",
    "        train_time_lst.append(train_time)\n",
    "        pred_time_lst.append(pred_time)\n",
    "        acc_lst.append(acc)\n",
    "        mat_lst.append(mat)\n",
    "        prec_lst.append(prec)\n",
    "        rcl_lst.append(rcl)\n",
    "        f1_lst.append(f1)\n",
    "\n",
    "    print()\n",
    "    print('Mean training time: {:.4f}s'.format(sum(train_time_lst)/len(train_time_lst)))\n",
    "    print()\n",
    "    print('Mean prediction time: {:.4f}s'.format(sum(pred_time_lst)/len(pred_time_lst)))\n",
    "    print()\n",
    "    print('Mean Accuracy: {:.4f}'.format(sum(acc_lst)/len(acc_lst)))\n",
    "    print()\n",
    "    print('All folds Confusion Matrix:')\n",
    "    print(np.sum(np.stack(mat_lst), axis=0))\n",
    "    print()\n",
    "    print('Mean Precision:')\n",
    "    print(np.mean(np.stack(prec_lst), axis=0))\n",
    "    print()\n",
    "    print('Mean Recall:')\n",
    "    print(np.mean(np.stack(rcl_lst), axis=0))\n",
    "    print()\n",
    "    print('Mean F1:')\n",
    "    print(np.mean(np.stack(f1_lst), axis=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    evaluate_n_fold(best_naive_bayes, folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour\n",
    "##### Investigate Hyperparameter Effects\n",
    "\n",
    "Investigate various distance functions. These were investigated first, as they have less of an impact on accuracy than the value of $k$. It is also important to reduce training time as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    dist_funcs = [manhattan, euclidean_squared, euclidean]\n",
    "    # Only run on the first fold to save time, as we only want an indication of which hyperparam value is best\n",
    "    fold = folds[0]\n",
    "    fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels = fold\n",
    "    \n",
    "    for dist in dist_funcs:\n",
    "        model = NearestNeighbour(k=5, dist=dist)\n",
    "        evaluate_model(model, fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate different values for $k$. It is also important to reduce training time as much as possible, whilst also obtaining reasonable accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    ks = [1, 2, 3, 5, 8, 13, 21, 34, 55]\n",
    "    \n",
    "    # Only run on the first fold to save time, as we only want an indication of which hyperparam value is best\n",
    "    fold = folds[0]\n",
    "    fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels = fold\n",
    "    \n",
    "    train_time_lst = []\n",
    "    pred_time_lst = []\n",
    "    acc_lst = []\n",
    "    mat_lst = []\n",
    "    prec_lst = []\n",
    "    rcl_lst = []\n",
    "    f1_lst = []\n",
    "    \n",
    "    for k in ks:\n",
    "        model = NearestNeighbour(k=k, dist=manhattan)\n",
    "        train_time, pred_time, acc, mat, prec, rcl, f1 = evaluate_model(model, fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels)\n",
    "        \n",
    "        train_time_lst.append(train_time)\n",
    "        pred_time_lst.append(pred_time)\n",
    "        acc_lst.append(acc)\n",
    "        mat_lst.append(mat)\n",
    "        prec_lst.append(prec)\n",
    "        rcl_lst.append(rcl)\n",
    "        f1_lst.append(f1)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    cls_map = ['T-shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    plt.figure(figsize = (20,20))\n",
    "    plt.rc('font', size=16)\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.plot(ks, train_time_lst, 'o-')\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.title('k vs Training time')\n",
    "    plt.ylabel('Training time (s)')\n",
    "    plt.xlabel('k')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.plot(ks, pred_time_lst, 'o-')\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.title('k vs Prediction time')\n",
    "    plt.ylabel('Prediction time (s)')\n",
    "    plt.xlabel('k')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.ylim(top=1)\n",
    "    plt.plot(ks, acc_lst, 'o-')\n",
    "    plt.title('k vs Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('k')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(3, 2, 4)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.ylim(top=1)\n",
    "    plt.plot(ks, np.mean(np.stack(prec_lst), axis=1), 'o-')\n",
    "    plt.title('k vs Mean class precision')\n",
    "    plt.ylabel('Mean class precision')\n",
    "    plt.xlabel('k')\n",
    "    # plt.legend(cls_map)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(3, 2, 5)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.ylim(top=1)\n",
    "    plt.plot(ks, np.mean(np.stack(rcl_lst), axis=1), 'o-')\n",
    "    plt.title('k vs Mean class recall')\n",
    "    plt.ylabel('Mean class recall')\n",
    "    plt.xlabel('k')\n",
    "    # plt.legend(cls_map)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(3, 2, 6)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.ylim(top=1)\n",
    "    plt.plot(ks, np.mean(np.stack(f1_lst), axis=1), 'o-')\n",
    "    plt.title('k vs Mean class F1')\n",
    "    plt.ylabel('Mean class F1')\n",
    "    plt.xlabel('k')\n",
    "    # plt.legend(cls_map)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_knn(train_data, train_labels, validation_data, validation_labels):\n",
    "    # Create and train model\n",
    "    model = NearestNeighbour(k=3, dist=manhattan)\n",
    "    return evaluate_model(model, train_data, train_labels, validation_data, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    evaluate_n_fold(best_knn, folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "##### Investigate Hyperparameter Effects\n",
    "\n",
    "1. Determine best network structure\n",
    "2. Determine best learning rate\n",
    "3. Determine appropriate number of epochs\n",
    "\n",
    "Only sigmoid activations were used as the model was either unstable for other activations or obviously much too slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    epochs = 500\n",
    "    eta = 0.01\n",
    "    batch_size = 64\n",
    "    activation = sigmoid\n",
    "    \n",
    "    models = [\n",
    "        NeuralNetwork([\n",
    "            FlatDenseLayer((784,), activation=activation),\n",
    "            FlatDenseLayer((10,), activation=activation),\n",
    "            FlatDenseLayer((10,), activation=sigmoid),\n",
    "        ], eta=eta, batch_size=batch_size, epochs=epochs, output=False),\n",
    "        NeuralNetwork([\n",
    "            FlatDenseLayer((784,), activation=activation),\n",
    "            FlatDenseLayer((10,), activation=activation),\n",
    "            FlatDenseLayer((10,), activation=activation),\n",
    "            FlatDenseLayer((10,), activation=sigmoid),\n",
    "        ], eta=eta, batch_size=batch_size, epochs=epochs, output=False),\n",
    "        NeuralNetwork([\n",
    "            FlatDenseLayer((784,), activation=activation),\n",
    "            FlatDenseLayer((100,), activation=activation),\n",
    "            FlatDenseLayer((10,), activation=activation),\n",
    "            FlatDenseLayer((10,), activation=sigmoid),\n",
    "        ], eta=eta, batch_size=batch_size, epochs=epochs, output=False),\n",
    "        NeuralNetwork([\n",
    "            FlatDenseLayer((784,), activation=activation),\n",
    "            FlatDenseLayer((100,), activation=activation),\n",
    "            FlatDenseLayer((20,), activation=activation),\n",
    "            FlatDenseLayer((10,), activation=sigmoid),\n",
    "        ], eta=eta, batch_size=batch_size, epochs=epochs, output=False),\n",
    "    ]\n",
    "\n",
    "    train_time_lst = []\n",
    "    pred_time_lst = []\n",
    "    acc_lst = []\n",
    "    mat_lst = []\n",
    "    prec_lst = []\n",
    "    rcl_lst = []\n",
    "    f1_lst = []\n",
    "    \n",
    "    # Only run on the first fold to save time, as we only want an indication of which hyperparam value is best\n",
    "    fold = folds[0]\n",
    "    fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels = fold\n",
    "    \n",
    "    for model in models:\n",
    "        train_time, pred_time, acc, mat, prec, rcl, f1 = evaluate_model(model, fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels)\n",
    "        \n",
    "        train_time_lst.append(train_time)\n",
    "        pred_time_lst.append(pred_time)\n",
    "        acc_lst.append(acc)\n",
    "        mat_lst.append(mat)\n",
    "        prec_lst.append(prec)\n",
    "        rcl_lst.append(rcl)\n",
    "        f1_lst.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The graphs for this section did not generate correctly, but this section would take too long to rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    epochs = 500\n",
    "    batch_size = 64\n",
    "    activation = sigmoid\n",
    "    etas = [0.1, 0.05, 0.025, 0.01, 0.005, 0.0025, 0.001, 0.0005, 0.00025, 0.0001]\n",
    "    \n",
    "    model = NeuralNetwork([\n",
    "        FlatDenseLayer((784,), activation=activation),\n",
    "        FlatDenseLayer((100,), activation=activation),\n",
    "        FlatDenseLayer((20,), activation=activation),\n",
    "        FlatDenseLayer((10,), activation=sigmoid),\n",
    "    ], eta=etas[0], batch_size=batch_size, epochs=epochs, output=False)\n",
    "\n",
    "    # Only run on the first fold to save time, as we only want an indication of which hyperparam value is best\n",
    "    fold = folds[0]\n",
    "    fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels = fold\n",
    "    \n",
    "    optimise_and_plot_learning_rate(etas, model, fold_train_data, fold_train_labels, fold_validation_data, fold_validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs for the section below are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_nn(train_data, train_labels, validation_data, validation_labels):\n",
    "    # Create and train model\n",
    "    model = NeuralNetwork([\n",
    "        FlatDenseLayer((784,), activation=sigmoid),\n",
    "        FlatDenseLayer((100,), activation=sigmoid),\n",
    "        FlatDenseLayer((20,), activation=sigmoid),\n",
    "        FlatDenseLayer((10,), activation=sigmoid),\n",
    "    ], eta=0.05, batch_size=64, epochs=250, output=False)\n",
    "    \n",
    "    return evaluate_model(model, train_data, train_labels, validation_data, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    evaluate_n_fold(best_nn, folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results of Best Classifiers of each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Linear Regression', 'Multinomial Linear Regression', 'Naive Bayes', 'K-Nearest Neighbour', 'Neural Network']\n",
    "mean_train_times = [86.3228, 54.3756, 0.3876, 0.0003, 171.4545]\n",
    "mean_predict_times = [0.0648, 0.0256, 0.0198, 148.2729, 0.0589]\n",
    "mean_accuracies = [0.8456, 0.7982, 0.6664, 0.8490, 0.8550]\n",
    "conf_mats = [\n",
    "    np.asarray([\n",
    "        [2392,    7,   39,   95,    9,    1,  443,    0,   10,    2],\n",
    "        [  16, 2901,    8,   34,    5,    0,    5,    0,    0,    1],\n",
    "        [  57,   16, 2287,   34,  282,    2,  379,    0,   12,    1],\n",
    "        [ 166,   74,   35, 2618,  117,    2,  103,    0,   33,    0],\n",
    "        [  14,    7,  350,   94, 2236,    0,  265,    0,    9,    0],\n",
    "        [   3,    0,    5,    2,    3, 2758,    7,  126,   24,   54],\n",
    "        [ 271,   15,  259,   96,  272,    1, 1764,    0,   57,    1],\n",
    "        [   2,    0,    0,    1,    0,  140,    3, 2781,   19,  119],\n",
    "        [  38,    1,   28,   10,   22,   34,   66,    9, 2800,    4],\n",
    "        [   1,    1,    0,    0,    1,   70,    0,  137,    2, 2832],\n",
    "    ]),\n",
    "    np.asarray([\n",
    "        [2120,    8,   57,  111,   14,    2,  389,    0,   30,    0],\n",
    "        [  27, 2897,   13,   79,   15,    3,   23,    0,    4,    1],\n",
    "        [  91,   12, 1814,   40,  344,    2,  317,    0,   34,    0],\n",
    "        [ 214,   74,   71, 2500,  126,    8,  182,    0,   31,    1],\n",
    "        [  23,   13,  521,  102, 2053,    2,  403,    0,   26,    0],\n",
    "        [   3,    1,    2,    0,    1, 2682,    0,  131,   22,   56],\n",
    "        [ 443,   11,  494,  124,  372,    3, 1657,    0,   69,    1],\n",
    "        [   2,    2,    0,    1,    0,  171,    0, 2745,   17,  201],\n",
    "        [  35,    3,   39,   26,   21,   46,   64,   16, 2729,    6],\n",
    "        [   2,    1,    0,    1,    1,   89,    0,  161,    4, 2748]\n",
    "    ]),\n",
    "    np.asarray([\n",
    "        [2343,   31,   15,  106,    3,    1,  648,    0,   15,    0],\n",
    "        [   4, 2700,    1,   33,    4,    0,    5,    0,    2,    0],\n",
    "        [  21,   37, 1783,    3,  542,    8,  477,    0,    6,    6],\n",
    "        [ 348,  207,   35, 2637,  404,    1,  223,    0,  144,    3],\n",
    "        [  17,    9,  837,   49, 1863,    3, 1098,    0,  211,    1],\n",
    "        [   0,    0,    0,    0,    0,  467,    0,   59,    6,  103],\n",
    "        [ 178,   36,  268,  152,  101,   23,  465,    0,  131,   40],\n",
    "        [   0,    0,    0,    0,    0, 1577,    0, 2795,   30,  339],\n",
    "        [  49,    2,   72,    4,   30,   23,  119,    3, 2420,    4],\n",
    "        [   0,    0,    0,    0,    0,  905,    0,  196,    1, 2518]\n",
    "    ]),\n",
    "    np.asarray([\n",
    "        [2534,   18,   67,  155,   25,    0,  565,    0,   23,    1],\n",
    "        [   5, 2914,    4,   26,    3,    0,    8,    0,    1,    1],\n",
    "        [  45,   16, 2387,   31,  458,    0,  422,    0,   46,    0],\n",
    "        [  64,   59,   18, 2587,   92,    3,   56,    0,   12,    0],\n",
    "        [  11,    3,  248,  116, 2089,    0,  188,    0,   23,    0],\n",
    "        [   0,    0,    0,    0,    0, 2651,    1,   31,   11,   10],\n",
    "        [ 285,   11,  282,   66,  273,    0, 1773,    0,   21,    1],\n",
    "        [   1,    0,    0,    0,    0,  217,    1, 2860,   25,  120],\n",
    "        [  15,    0,    5,    3,    7,    3,   21,    1, 2795,    0],\n",
    "        [   0,    1,    0,    0,    0,  134,    0,  161,    9, 2881]\n",
    "    ]),\n",
    "    np.asarray([\n",
    "        [2365,    9,   52,  102,   10,    0,  398,    0,   15,    1],\n",
    "        [  12, 2926,    6,   40,    6,    2,    6,    0,    3,    0],\n",
    "        [  56,    8, 2320,   27,  282,    2,  296,    0,   15,    0],\n",
    "        [ 123,   60,   33, 2610,  111,    1,   96,    0,   21,    1],\n",
    "        [  15,    9,  317,   99, 2275,    0,  233,    0,   16,    3],\n",
    "        [   5,    1,    1,    2,    1, 2799,    4,  121,   25,   48],\n",
    "        [ 353,    7,  265,   92,  238,    4, 1947,    0,   58,    1],\n",
    "        [   0,    1,    0,    3,    2,  116,    1, 2778,   11,  126],\n",
    "        [  28,    1,   16,    7,   22,   14,   51,    8, 2797,    2],\n",
    "        [   3,    0,    1,    2,    0,   70,    3,  146,    5, 2832]\n",
    "    ])\n",
    "]\n",
    "\n",
    "mean_precisions_by_class = [\n",
    "    np.asarray([0.79985467, 0.97691669, 0.74694781, 0.8330888,  0.75214043, 0.92503362, 0.64921367, 0.90755323, 0.93001218, 0.93055809]),\n",
    "    np.asarray([0.79839245, 0.94701683, 0.73793274, 0.79150497, 0.70485267, 0.92682741, 0.60545925, 0.87912836, 0.91506139, 0.91745585]),\n",
    "    np.asarray([0.74157424, 0.98229906, 0.61906961, 0.66011596, 0.45564595, 0.7376524, 0.33441587, 0.58971677, 0.88814489, 0.69588295]),\n",
    "    np.asarray([0.74838203, 0.98388233, 0.70179857, 0.89539027, 0.7804547,  0.98052861, 0.65385576, 0.88746578, 0.98078678, 0.90433979]),\n",
    "    np.asarray([0.8017319, 0.97504806, 0.77303743, 0.85552346, 0.76848373, 0.93091832, 0.65996621, 0.91445806, 0.94983404, 0.92505939])\n",
    "]\n",
    "\n",
    "mean_recalls_by_class = [\n",
    "    np.asarray([0.80810811, 0.95996328, 0.75952454, 0.87734058, 0.75871094, 0.91689701, 0.58118812, 0.91092146, 0.94403381, 0.93962509]),\n",
    "    np.asarray([0.71621622, 0.95863113, 0.60239599, 0.83782631, 0.69672086, 0.89161794, 0.54597555, 0.89908175, 0.92010647, 0.91178302]),\n",
    "    np.asarray([0.79155405, 0.89345398, 0.59216849, 0.88371417, 0.63213536, 0.15526024, 0.15321022, 0.91549127, 0.81593184, 0.83545687]),\n",
    "    np.asarray([0.85608108, 0.96426573, 0.79275373, 0.86695248, 0.70884469, 0.88131672, 0.58417904, 0.93678024, 0.94234917, 0.95588766]),\n",
    "    np.asarray([0.79898649, 0.96823924, 0.770499,   0.87465938, 0.77196011, 0.93052049, 0.64151902, 0.90992393, 0.94302257, 0.93962289])\n",
    "]\n",
    "\n",
    "mean_f1s_by_class = [\n",
    "    np.asarray([0.80288307, 0.96830781, 0.75212007, 0.8539681,  0.75462026, 0.92085224, 0.60989431, 0.90911391, 0.93677903, 0.93496731]),\n",
    "    np.asarray([0.74256119, 0.952461,   0.61258572, 0.80815645, 0.67354938, 0.90837514, 0.50565056, 0.88522393, 0.91709617, 0.91290083]),\n",
    "    np.asarray([0.76548335, 0.93564555, 0.60474426, 0.75538131, 0.5293982, 0.25633562, 0.20990478, 0.71726538, 0.85029551, 0.75918138]),\n",
    "    np.asarray([0.79846003, 0.97393321, 0.74402335, 0.88074636, 0.74275956, 0.92818834, 0.61672485, 0.91133918, 0.96112016, 0.9293543]),\n",
    "    np.asarray([0.79982213, 0.97161431, 0.77121738, 0.86451959, 0.76796481, 0.93068221, 0.64932603, 0.91215338, 0.94615582, 0.9322106])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results\n",
    "#### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    # A lot of the code to generate heatmaps is taken from this website:\n",
    "    # https://matplotlib.org/3.1.1/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "    cls_map = ['T-shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "    model_idx = 0\n",
    "    for mat in conf_mats:\n",
    "        fig, ax = plt.subplots(figsize=(20, 16))\n",
    "        im = ax.imshow(mat)\n",
    "        ax.set_xticks(np.arange(mat.shape[1]))\n",
    "        ax.set_yticks(np.arange(mat.shape[0]))\n",
    "        ax.set_xticks(np.arange(mat.shape[1]+1)-.5, minor=True)\n",
    "        ax.set_yticks(np.arange(mat.shape[0]+1)-.5, minor=True)\n",
    "        \n",
    "        ax.set_xticklabels(cls_map)\n",
    "        ax.set_yticklabels(cls_map)\n",
    "        \n",
    "        cbar = ax.figure.colorbar(im, ax=ax)\n",
    "        \n",
    "        # Let the horizontal axes labeling appear on top.\n",
    "        ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=True, labelbottom=False)\n",
    "    \n",
    "        # Rotate the tick labels and set their alignment.\n",
    "        plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "                 rotation_mode=\"anchor\")\n",
    "        \n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        for i in range(len(cls_map)):\n",
    "            for j in range(len(cls_map)):\n",
    "                text = ax.text(j, i, mat[i, j], ha=\"center\", va=\"center\", color=\"w\", size=24)\n",
    "\n",
    "        ax.set_title(\"Cumulative Confusion Matrix\\nfor Best {} Model\".format(model_names[model_idx]))\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        model_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    # A lot of the code to generate heatmaps is taken from this website:\n",
    "    # https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/barchart.html#sphx-glr-gallery-lines-bars-and-markers-barchart-py\n",
    "    cls_map = ['T-shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    \n",
    "    x = np.arange(len(cls_map))\n",
    "    width = 0.1  # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,16))\n",
    "    for i in range(len(model_names)):\n",
    "        rects1 = ax.bar(x - width/2 + width*i, mean_precisions_by_class[i], width, label=model_names[i])\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title('Mean Precision by Class across 10 folds')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(cls_map)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    # A lot of the code to generate heatmaps is taken from this website:\n",
    "    # https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/barchart.html#sphx-glr-gallery-lines-bars-and-markers-barchart-py\n",
    "    cls_map = ['T-shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    \n",
    "    x = np.arange(len(cls_map))\n",
    "    width = 0.1  # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,16))\n",
    "    for i in range(len(model_names)):\n",
    "        rects1 = ax.bar(x - width/2 + width*i, mean_recalls_by_class[i], width, label=model_names[i])\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Recall')\n",
    "    ax.set_title('Mean Recall by Class across 10 folds')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(cls_map)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_best_only:\n",
    "    # A lot of the code to generate heatmaps is taken from this website:\n",
    "    # https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/barchart.html#sphx-glr-gallery-lines-bars-and-markers-barchart-py\n",
    "    cls_map = ['T-shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    \n",
    "    x = np.arange(len(cls_map))\n",
    "    width = 0.1  # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,16))\n",
    "    for i in range(len(model_names)):\n",
    "        rects1 = ax.bar(x - width/2 + width*i, mean_f1s_by_class[i], width, label=model_names[i])\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('F1')\n",
    "    ax.set_title('Mean F1 by Class across 10 folds')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(cls_map)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
